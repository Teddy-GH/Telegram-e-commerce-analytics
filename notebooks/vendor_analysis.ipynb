{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vendor Analysis: Lending Scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>7383</td>\n",
       "      <td>üí•Miralux Hot plate\\n ·â£·àà·àÅ·àà·âµ ·àù·ãµ·åÉ ·àµ·â∂·â≠\\n\\n¬†¬†¬†¬†¬† üíØo...</td>\n",
       "      <td>2025-06-19 06:31:31+00:00</td>\n",
       "      <td>data/photos/@Shageronlinestore_7383.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>7382</td>\n",
       "      <td>üí•7pcs glass water set\\n\\n‚úîÔ∏è ·ä†·äï·ãµ ·àõ·à´·ä™ ·åÜ·åç·äì 6 ·àò·å†·å´ ...</td>\n",
       "      <td>2025-06-18 11:19:11+00:00</td>\n",
       "      <td>data/photos/@Shageronlinestore_7382.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>7381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-18 11:19:11+00:00</td>\n",
       "      <td>data/photos/@Shageronlinestore_7381.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>7380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-18 11:19:11+00:00</td>\n",
       "      <td>data/photos/@Shageronlinestore_7380.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>7379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-18 11:19:11+00:00</td>\n",
       "      <td>data/photos/@Shageronlinestore_7379.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Channel Title    Channel Username    ID  \\\n",
       "0  Sheger online-store  @Shageronlinestore  7383   \n",
       "1  Sheger online-store  @Shageronlinestore  7382   \n",
       "2  Sheger online-store  @Shageronlinestore  7381   \n",
       "3  Sheger online-store  @Shageronlinestore  7380   \n",
       "4  Sheger online-store  @Shageronlinestore  7379   \n",
       "\n",
       "                                             Message  \\\n",
       "0  üí•Miralux Hot plate\\n ·â£·àà·àÅ·àà·âµ ·àù·ãµ·åÉ ·àµ·â∂·â≠\\n\\n¬†¬†¬†¬†¬† üíØo...   \n",
       "1  üí•7pcs glass water set\\n\\n‚úîÔ∏è ·ä†·äï·ãµ ·àõ·à´·ä™ ·åÜ·åç·äì 6 ·àò·å†·å´ ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                        Date                               Media Path  \n",
       "0  2025-06-19 06:31:31+00:00  data/photos/@Shageronlinestore_7383.jpg  \n",
       "1  2025-06-18 11:19:11+00:00  data/photos/@Shageronlinestore_7382.jpg  \n",
       "2  2025-06-18 11:19:11+00:00  data/photos/@Shageronlinestore_7381.jpg  \n",
       "3  2025-06-18 11:19:11+00:00  data/photos/@Shageronlinestore_7380.jpg  \n",
       "4  2025-06-18 11:19:11+00:00  data/photos/@Shageronlinestore_7379.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/telegram_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "ner_pipeline = pipeline(\"token-classification\", model=\"Davlan/bert-base-multilingual-cased-ner-hrl\", aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "def analyze_vendors(df, ner_pipeline):\n",
    "    # df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    vendors = df['vendor'].unique()\n",
    "\n",
    "    vendor_metrics = []\n",
    "\n",
    "    for vendor in vendors:\n",
    "        vendor_df = df[df['vendor'] == vendor].copy()\n",
    "        vendor_df.sort_values(\"timestamp\", inplace=True)\n",
    "\n",
    "        # Posts/week\n",
    "        days_range = (vendor_df['timestamp'].max() - vendor_df['timestamp'].min()).days or 1\n",
    "        posts_per_week = len(vendor_df) / (days_range / 7)\n",
    "\n",
    "        # Views\n",
    "        avg_views = vendor_df['views'].mean()\n",
    "        top_post = vendor_df.loc[vendor_df['views'].idxmax()]\n",
    "        top_product = top_post['text']\n",
    "        top_views = top_post['views']\n",
    "\n",
    "        # Price extraction\n",
    "        prices = []\n",
    "        for text in vendor_df['text']:\n",
    "            preds = ner_pipeline(text)\n",
    "            price_tokens = [p['word'] for p in preds if 'PRICE' in p['entity']]\n",
    "            joined = \" \".join(price_tokens).replace(\",\", \"\").replace(\"ETB\", \"\")\n",
    "            for token in joined.split():\n",
    "                try:\n",
    "                    val = float(token)\n",
    "                    prices.append(val)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        avg_price = np.mean(prices) if prices else 0.0\n",
    "\n",
    "        # Lending Score (simple weights)\n",
    "        score = (avg_views * 0.5) + (posts_per_week * 0.5)\n",
    "\n",
    "        vendor_metrics.append({\n",
    "            \"vendor\": vendor,\n",
    "            \"Posts/Week\": round(posts_per_week, 2),\n",
    "            \"Avg Views/Post\": round(avg_views, 2),\n",
    "            \"Avg Price (ETB)\": round(avg_price, 2),\n",
    "            \"Top Product\": top_product,\n",
    "            \"Top Views\": top_views,\n",
    "            \"Lending Score\": round(score, 2)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(vendor_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e560ac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:\\10-academy\\Week4\\Telegram-e-commerce-analytics\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "import sys \n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from transformers import pipeline\n",
    "from scripts.vendor_scorecard_engine import score_vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0c5259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load scraped Telegram data\n",
    "df = pd.read_csv(\"../data/telegram_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bca58af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after load: ['channel title', 'channel username', 'id', 'message', 'date', 'media path']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Normalize column names\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "print(\"Columns after load:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "495b6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match expectations in score_vendors\n",
    "df.rename(columns={\n",
    "    'channel title': 'vendor',\n",
    "    'message': 'text',\n",
    "    'date': 'timestamp'\n",
    "}, inplace=True)\n",
    "\n",
    "# Simulate 'views' since missing from data\n",
    "np.random.seed(42)\n",
    "df['views'] = np.random.randint(100, 5000, size=len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae2cf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parse timestamps and drop rows with invalid timestamps\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "if df['timestamp'].isnull().any():\n",
    "    print(f\"Dropping {df['timestamp'].isnull().sum()} rows with invalid timestamps\")\n",
    "    df = df.dropna(subset=['timestamp'])\n",
    "\n",
    "# Remove timezone info if present (to avoid warnings in score_vendors)\n",
    "df['timestamp'] = df['timestamp'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c52e6e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "# Load your model (replace with your model path or Hugging Face model name)\n",
    "model_name = \"Davlan/afro-xlmr-base\"  # or \"models/saved_model_dir\" for local fine-tuned model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Now define the NER pipeline\n",
    "ner_pipeline = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07710094",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = score_vendors(df, ner_pipeline)\n",
    "\n",
    "# Save results\n",
    "score_df.to_csv(\"../data/vendor_scorecard.csv\", index=False)\n",
    "\n",
    "# Display head of results\n",
    "print(score_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
